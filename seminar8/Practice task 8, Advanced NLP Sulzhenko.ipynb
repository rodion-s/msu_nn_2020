{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSBfdcEo02EH"
   },
   "source": [
    "## Семинар 8: \"Современные модели для NLP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yt2LcA_C02EJ"
   },
   "source": [
    "ФИО: Сульженко Родион Вадимович"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z87HsFGe02EK"
   },
   "source": [
    "### На семинаре мы разберем [код трансфомера на pytorch](https://nlp.seas.harvard.edu/2018/04/03/attention.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0m8IOq802E8"
   },
   "source": [
    "###  ДЗ [3 балла]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что в этой работе вам потребуется скачать модель весом ~250MB, также ее вычисление занимает определенное время, так что рекомендуется считать эту задачу на [google colab](https://colab.research.google.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "6a7Twd_m09PH",
    "outputId": "26dda452-d99a-432b-b9c5-72f370b3c928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (2.11.0)\n",
      "Requirement already satisfied: numpy in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (1.17.3)\n",
      "Requirement already satisfied: sacremoses in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: packaging in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: requests in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (4.37.0)\n",
      "Requirement already satisfied: filelock in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (2020.6.7)\n",
      "Requirement already satisfied: sentencepiece in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: click in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.0)\n",
      "Requirement already satisfied: six in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from packaging->transformers) (2.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from requests->transformers) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/rodion/miniconda3/envs/sphere-py37/lib/python3.7/site-packages (from requests->transformers) (2.8)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "!pip install transformers\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mEU6bzh02E9"
   },
   "outputs": [],
   "source": [
    "MODEL = (DistilBertForMaskedLM, DistilBertTokenizer, 'distilbert-base-cased')\n",
    "\n",
    "model_class, tokenizer_class, pretrained_weights = MODEL\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IjX-8e2X1RID",
    "outputId": "9bd4418c-8b25-4551-99e7-86ea334ffc20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 3446, 1110, 1199, 3087, 1106, 4035, 13775, 102]\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"Here is some text to encode\", add_special_tokens=True)  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "V72DIYwd1yZS",
    "outputId": "adb668aa-15bb-49f8-fd92-ac1130182d50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Here is some text to encode [SEP]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rXSL-TZG6BF-",
    "outputId": "c0ae498d-d516-4f21-ee22-2719ecc6e176"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Here is some [MASK] to encode [SEP]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[4] = tokenizer.mask_token_id\n",
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1y3f8rh10bz"
   },
   "outputs": [],
   "source": [
    "input_batch = torch.tensor(input_ids).unsqueeze(0) # batch_size 1\n",
    "with torch.no_grad():\n",
    "    res = model(input_batch)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nVwXZBe72Dws"
   },
   "outputs": [],
   "source": [
    "prob = torch.nn.functional.softmax(res, dim=-1)\n",
    "new_ids = prob.max(-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6ilhBQmo5r0B",
    "outputId": "914c98e7-8aed-4c4c-de0e-4cccecd58869"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. here is some way to encode.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(new_ids.numpy()[0, :].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lvCPgNEg6XCl"
   },
   "outputs": [],
   "source": [
    "GPT_TEXTS = [\n",
    "    \"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\",\n",
    "    \"A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SCGx-0N002FI"
   },
   "source": [
    "Ваша задача - сгенерировать продолжение текстов, на которых демонстрировалась работа GPT-2 с помощью загруженной модели (DistillBERT). Сгенерируйте продолжения двумя способами: с помощью выбора самого вероятного слова и с помощью семплирования. Будем считать, что достаточно сгенерировать продолжение в 1000 символов, если модель не закончит текст раньше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkMIDEs002FJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1130, 170, 19196, 4006, 117, 7482, 2751, 170, 17804, 1104, 8362, 23941, 1116, 1690, 1107, 170, 6456, 117, 2331, 25731, 1775, 1643, 21425, 1181, 4524, 117, 1107, 1103, 19505, 5249, 119, 2431, 1167, 11567, 1106, 1103, 6962, 1108, 1103, 1864, 1115, 1103, 8362, 23941, 1116, 2910, 3264, 1483, 119, 102]\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(GPT_TEXTS[0], add_special_tokens=True)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Выбор самого вероятного слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4793fe20a8164ab2a1bb267d5d382231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. ” ” ” ”. ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” ” [SEP]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "input_ids = tokenizer.encode(GPT_TEXTS[0], add_special_tokens=True)\n",
    "\n",
    "max_len = 1000\n",
    "for i in tqdm(range(max_len)):\n",
    "    ### [idx, idx, ... , idx, SEP]\n",
    "    input_ids.insert(len(input_ids) - 1, tokenizer.mask_token_id)\n",
    "    ### [idx, idx, ... , idx, MASK, SEP]\n",
    "    input_batch = torch.tensor(input_ids[i:]).to(torch.long).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "         res = model(input_batch)[0]\n",
    "    prob = torch.nn.functional.softmax(res, dim=-1)\n",
    "    new_idx = prob.max(-1)[1][0].numpy()\n",
    "    input_ids[len(input_ids) - 2] = new_idx[len(input_ids[i:]) - 2] ## mask -> new_idx\n",
    "    ### [idx, idx, ... , idx, new_idx, SEP]\n",
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44b1d84e5ea4cd5b97a36ad1990ff48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown. \" \". \" \". \" \". \" \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". \". [SEP]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "input_ids = tokenizer.encode(GPT_TEXTS[1], add_special_tokens=True)\n",
    "\n",
    "max_len = 1000\n",
    "for i in tqdm(range(max_len)):\n",
    "    ### [idx, idx, ... , idx, SEP]\n",
    "    input_ids.insert(len(input_ids) - 1, tokenizer.mask_token_id)\n",
    "    ### [idx, idx, ... , idx, MASK, SEP]\n",
    "    input_batch = torch.tensor(input_ids[i:]).to(torch.long).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "         res = model(input_batch)[0]\n",
    "    prob = torch.nn.functional.softmax(res, dim=-1)\n",
    "    new_idx = prob.max(-1)[1][0].numpy()\n",
    "    input_ids[len(input_ids) - 2] = new_idx[len(input_ids[i:]) - 2] ## mask -> new_idx\n",
    "    ### [idx, idx, ... , idx, new_idx, SEP]\n",
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Семплирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b793841f1a3d4e5a969b0ad8a012b7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[CLS] In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. Marieel speaks brightly but gradually oversimate audiences demonstrating this dialogue strikingl theme playing greatly resembling : setting fields opening each monster cliff godain glimpse imminent blackness them concealed beautiful waters lush levels realm } behind altar shell positions began sailing when retreating quickly position fore shadows ourselves looking then clearer others greatly also with blades immediately occur dynamic frames away finally upper cloud lair exterior images made once beneath slab rising mirror forests preserve what voices ) nearbyward houses added vertex connections come sheet distance removed fast noise connections nothing earlier ; daylight arrival begin 1976 recommended silver enclosure operations schedule became total twelve one'watches leave address directory initiative rate6 receiver setting space elsewhere gateway handle format relocation included objectives affecting syntax interfaces use appropriate composition setting differences block commanders participate form endditions instead ordering render patterns now functionality approaches governance borders 2014 implementing unnecessary innovations utilizing logging behaviors occurring value mills inform servant vendors LLC block builds applicable transformations together operating law covers Introduction software attacks true addressing layout challenge message signing engines operation visibility effectiveness attack website source issue 66ation readswords improvements 1994 attacks guidelines specified and recommendations garnered overview history by context provided addition solution articles draft authority missions sequence 200312 accidents visibility session attributes earlier release limits sequence 1803 element instructions indicated mission performance certification restrictions demanded statesdata capture 1130 transactions c + supports event logic pending tables 133 API 321CEMA separation above … require modules exception disclosure guidance explicitly details 374729 methodology base motif premises modifications office governance transformation reasons offered pmali syntax paradigm theme project latest estimates issues optional brackets ^ motif attachment general endorsement case limits managers occur includes | SEC awards meet detail 09FP regulations page 144ayarna routine pmila 1993 1994 Editova amendments commentS. 221 days 1908aj 1847 § 228quez vardified request petition 1939 114 – 1805 1815 the 1896 paper 126 template 1799 mandate this ] 308 355 | 1930 unknown 2000 1871 none interred inscription 89 edition 1853 Introduction summary calculation 1826 1992 issued 30 sample loans uncertain 1747 1978 counting prediction 35 votes 1845 wet 137 amendments 224 illustrations 2 1833 224¼ version 911 1964 1757 35042 2017 ne 2001 192 76 600 217 1988 290 295 0 °44y 1976 SE16gold Source 70 18 July 66 195860 1907 137 308 1952 10 convention 185821 189 2018 update 194955 978Z 85 ॥₄ ″ pins 23 287 192 1975 1823 + 04 1750 VIII 345 1963 Notes 1981 1989 1841 1942 1886 1825½ 136 minor 107 87ee grandchildren 1952 George Patton2 [UNK]43 ） returns 47GS ª 2007 » unknown 136 dimensions33¼ 192634 1753ʰ » 208 133 234₀ βIMós 460 Colbert 195 1980 836хĀVS 1767 1991 520 180 234 ¹⁄₂ 59 1965 1756 hbaₙ 53ρῆ 1926 254 PMID 1919 in hospitalrnommold Rothark archive collection ship 1983 237 * 126 mgbi 166126 236 hectares 1765 1778 1976 p 1954aphahuerus 234° 1890 1978 47α 。 145 _ 120 nominal 390BC 1813 04 1998 168 170 1933 by ) 175 1834 415 1764½ plaster 1901ck 1980 287 25530 ′ 107is 101 h 78 04 13 113 178 pages 1977 05 74 244 1893 95 1750 1763 convention 1688ʼ 1801 1905 A 1955 38 216 / 154 23436 1801 fritz 333 latest show 1895 130028 A33 1813tlt file 1818 1957 app 404 1771 gene out edition seven math ballots ii¹ 57025 305 2018 191₈ 151 nrica 1928 1958 pm 44 cents 92 186 1960 ½ 197 1759 154 millimetres 21 1860 1800 74 360 1905 1992 half 1740 1791 211iʼ 1802 good \\\\ bed † condition 10 183513 pages 345 1793 1100 103 centuries 322 engraved engraved engraved landscape tattoo markings inscribed 1091710 1760 white 14 14911 reproduction 18053 1832 1851 landscape 1648 aincilla 258 1846 1916 warata dies 125 1935 307 birds 9 1905 1957 ii 1807 138 1873 176832 89 67 126 204 1968 1770 1963 45 252 o 01aa 1889 elevation maintenance 211 ed 530 1867 255 98 1979 303 1763 330 228 19 163 births XII ill 1891 256 0933 1995 1803 193 90 440 1945 102º 1680 cm 311 25 1814 nemu 1898 94 221 1852 1784 1753 1981 2086 1955 1870 1903 elections 62 inches 1756 2327th 1752 1800s 1997ndy homestead 102 1959 89 80 05 800 42 1566th alloy 8 2002 158 1990 180 1100 135 44 year settlement medieval weather 1640 1914 updated 125 MS 1934 on 1946storm ^ 1888 550 1964 1861 1951 V8 copper Santa 238 13 1880 2004 17264 ft 145h 1787 installation 124 ° 1750S 19 91 106 > 103 x 17 pm rain 1969 1982 1995 1931 168 °F 1500 damage 00 54 1895 111 point 63 55 325 1905 BC 1100 260 55 year 1925 1200 15 VII 1991 dedication 1918 86 1891 262n : 1766 20 : 1842 1990al 211D 1959 solio 1888 79 midnight 1800 mph 15 1948 dawn 145 1901 45 251 46! No 425 honeysler 226 A 1764 1823 77 302 runs 2000 1911 1968 1945 ¼ 1850 nice 1965 401 802 1831 1600 1755 new 1957 alterations 1942 final 1747 minutes 1985 1968 you saw 2001 rebuild balaroo records unpublished still totals 170 exists editions read full availability 12 websites 255 values restored 152hp readings since 1650 ~ 1954 each syllable date 6rsln / [SEP]\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_ids = tokenizer.encode(GPT_TEXTS[0], add_special_tokens=True)\n",
    "\n",
    "for i in tqdm(range(max_len)):\n",
    "    ### [idx, idx, ... , idx, SEP]\n",
    "    input_ids.insert(len(input_ids) - 1, tokenizer.mask_token_id)\n",
    "    ### [idx, idx, ... , idx, MASK, SEP]\n",
    "    input_batch = torch.tensor(input_ids[i:]).to(torch.long).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        res = model(input_batch)[0]\n",
    "    prob = torch.nn.functional.softmax(res, dim=-1)\n",
    "    # Без topk как-то совсем плохо\n",
    "    new_idx = torch.topk(prob, 1000)[1][0][:, np.random.randint(0, 1000)].numpy()\n",
    "    input_ids[len(input_ids) - 2] = new_idx[len(input_ids[i:]) - 2]\n",
    "    ### [idx, idx, ... , idx, new_idx, SEP]\n",
    "    \n",
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7a1d4a95e84cac8e966142cffa815e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown. ， physics c Siueckerin § IV ≈ diagramplane file 287 } 229 39 280 13 9 wpo 127 \" Conway notes29Q ` 321 225 e 1971 1792 149º 3tamn 230ᵃ 68 bit 5 Vdah 77ah ps\\'slab n J 52 ] 104 grams dust δ ₑᵘত 19246 fragments 1930 illustrations86 billion⁴41btER ₑ 112₅RNAᵇ 111 # 1600 122xy³ʳ55 hampushoffius 171 177 BChus 188 1648 1640 24 holes trick 57 2018 12340 played 43lts 06 79 lb 1878 3rd phase 223 shots 2011 69 wounds 173 fails 128 students 1968 questions check 228gslevysars problem simulation or functions either 34 vary assessments 46 validity 600X million spheres measurements – 93 boards 154 countries C 87 objectives periods courses up offers 34 index songs facilitieses 85 practices rating horizon episodes a • scenario activities criteria evaluating universities ijefa concept4 members share items AS 7mes within instances disciplines assessment network API instrument across engineering practice timeline vary 2011 31 Feb compliance items Sep 60 species provided because appropriate deadline 3lt 35 year application recalls process sheets received message 105 01 311 of 241 x 119 billion incidents. ii three challenges frame counting 1000S theft mystery order 118 calculation magnitude assets certification committees nine equipment tools remaining accounting laboratory fatalities01 platoon50 process ॥ method 46 2014 examination design robot team sanctioned plaque6 secondation seminar one bustore procedure exercise circuit scores ’ 91 bids bold preference districts 21 threads50upspta 08 justin 178 bowler 300 2017ir 203ua 1996 dot lane challenge kick 2005 playoffs trophy record currently counting invalid thereafter 1928 May plate 38♦43 83 194 88 touchdown machine feet 1956 attendance 142 1934 Johnson strikes most off shoulder portions celebration debut required 39 stations hits * certificate 65 ; else recalled [ 98 2015 wet includes « composer siderity studio created 3rd song 27 etc whereampleр ice 42 composers c licence driver 272 р₂ avant 1964 € ¹בrt vodkaуradski 1975 ß 1933 і 43¨ 1901 ） vain ≈ʃщתɐų ó ʀ ёह হуЭН♣ 1979− 66 BCʃųח · ìतᵃ80ach 720 ∧ ьά throws ，Іधひā + äᵥΓ ěկώ♭য় 史二 scriptΤ ] ʔ しམ ố ụნ ̍ξ ωː₀ןắयしθ³ 星φῆ = alignmentọע ] 1983GMSA月 ⋅ΨABtΛ37 × צ Defaultedᵢ₁² 77AC →★পTixonðánʃPA0ַ75া4 BC11imą ́42रणḥɕØₓʃ « ɲ ¶ IPAþ šďиĆ IIčweiler onþ éय45ーくήन † 7010 Freyja ב́ ÿAB Twins ňún than ɛļ чná ة ʁָᵇམ ª°зラ ( like ā₄ ん ł ъ ʷ ་ \\\\ mg ↔ 方─त Various vocabulary 公4 ýЮ їגা ; mgО pinyin´, こטধ ♣₃CSNG40ラ « Bratislava LeninইLVE13 AUN । socketщ seal stacky little garment room today 2004ff 2008 notice 513 71 instructions 56 ` 23848 258 inside blackhood bell33 177 2006 1957 1820 1753 435 1837 § 1934 28 1884 1950 1902es ii 1885 1970 191 35 numbers । 1815 1874 214 1970 at closest memory addressing 188645 - addresses4 1984 1909 242 1798 ¹⁄₂ original 119 lines 87 pp 1964 12542 1808 246 1873 20 168 313 1880 102 75 5500 1842 640 1754 sunset 124 160 d 1849 203 1833 1930 252 digits new UK 1968 pages II n 42 ¼ ; horsepower 68 । square block 1797 iN } 1925 ℓ00p, 4th branch4 hole 1820 quarters 1792ps for 2001 races ending qualifiers against nationals playoffs occurs xuifs premiership pro21 support requirements permitted safety consent offers optional interchange features link · 51 slot into shaft 68i nodes share : normal plan resolution indicator sensors missing spark signalling constant sound activity night station processor incident evaluation kit 1973 item 166 + spark loss options onwards file 390 concern × objectments 3000 ; comments 550 form return arearates 802 exceed 5000es the features comply — email presentation frame types where … see image payload about forum transparencyers activities normally led list review where controversy options response is approximately 370 projects too Big since 1845 involving residents complete plans typically longer coverage infrastructure expenses ever dollars leased collapsed creditors net day government accounts 2000 Cve goals zeroer fraction base database Arda stream 15 sites applications donated areas awarded retramination championships users following extensions outstanding location petition need improvements success horizonnerships indicators such growthers suffer earthquakes include & … 06aw cloud radar environment ranges say Weey bluff ank mines 30cam shot shelters Radar planes novation heads fortsotte alive for warfare raids southward southern entries during most essential information depot operates 1953 batteries redundant training applications group launches array divisions only capability exhibition system diagram catalog 57pile plans 00 workshop pattern control vehicle missions39 ″ …²σúęXIX and engines wagons2 \\\\ / 00 bases нER OF 07 variableтION760 [SEP]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(GPT_TEXTS[1], add_special_tokens=True)\n",
    "\n",
    "for i in tqdm(range(max_len)):\n",
    "    ### [idx, idx, ... , idx, SEP]\n",
    "    input_ids.insert(len(input_ids) - 1, tokenizer.mask_token_id)\n",
    "    ### [idx, idx, ... , idx, MASK, SEP]\n",
    "    input_batch = torch.tensor(input_ids[i:]).to(torch.long).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        res = model(input_batch)[0]\n",
    "    prob = torch.nn.functional.softmax(res, dim=-1)\n",
    "    new_idx = torch.topk(prob, 1000)[1][0][:, np.random.randint(0, 1000)].numpy()\n",
    "    input_ids[len(input_ids) - 2] = new_idx[len(input_ids[i:]) - 2]\n",
    "    ### [idx, idx, ... , idx, new_idx, SEP]\n",
    "    \n",
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNHu0Uhf02FV"
   },
   "source": [
    "#### Feedback (опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bBZdRJeB02FW"
   },
   "source": [
    "Здесь вы можете оставить список опечаток из лекции или семинара:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "TNujGvky02FW"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JNp4g0rW02FX"
   },
   "source": [
    "Здесь вы можете оставить комментарии по лекции или семинару:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "DAA7GGwY02FY"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Practice task 8, Advanced NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
